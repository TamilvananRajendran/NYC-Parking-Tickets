{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York City is a thriving metropolis. Just like most other metros its size, one of the biggest problems its citizens face is parking. The classic combination of a huge number of cars and cramped geography leads to a huge number of parking tickets.\n",
    "#### In an attempt to scientifically analyse this phenomenon, the NYC Police Department has collected data for parking tickets. Of these, the data files for multiple years are publicly available on Kaggle. We will try and perform some exploratory analysis on #a part of this data. Spark will allow us to analyse the full files at high speeds as opposed to taking a series of random #samples that will approximate the population. For the scope of this analysis, we will analyse the parking tickets over the year 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class pyspark.sql.SparkSession, The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "#A SparkSession can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and \n",
    "# read parquet files.To create a SparkSession, use the following builder pattern:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"NYC Parking Ticket Assignment\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Datafram can be created by by calling read method on spark object\n",
    "\n",
    "tickets = spark.read.csv(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\", inferSchema=True,header=True)\n",
    "tickets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|Total Count Of Tickets(2017)|\n",
      "+----------------------------+\n",
      "|                     5431918|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.the total number of tickets for the year 2017\n",
    "from pyspark.sql.functions import count, year\n",
    "\n",
    "total_ticket_count_2017 = tickets.filter(year(\"Issue Date\")==2017).agg(count(\"Summons Number\"))\n",
    "total_ticket_count_2017 = total_ticket_count_2017.withColumnRenamed(\"count(Summons Number)\", \"Total Count Of Tickets(2017)\")\n",
    "total_ticket_count_2017.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4273951|\n",
      "|                NJ| 475825|\n",
      "|                PA| 140286|\n",
      "|                CT|  70403|\n",
      "|                FL|  69468|\n",
      "+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the number of parking tickets per unique states from where the cars that got parking tickets came.\n",
    "from pyspark.sql.functions import count, countDistinct, desc, regexp_replace, sum, col\n",
    "\n",
    "unique_states = tickets.filter(year(\"Issue Date\")==2017).groupby(\"Registration State\")\\\n",
    "                .agg(countDistinct(\"Summons Number\"))\n",
    "unique_states = unique_states.withColumnRenamed(\"count(DISTINCT Summons Number)\",\"count\")\n",
    "unique_states.sort(desc(\"count\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4290006|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replacing 99 in Registration State with NY\n",
    "state_replace = unique_states.withColumn(\"Registration State\", regexp_replace(\"Registration State\", \"99\", \"NY\"))\n",
    "state_replace = state_replace.where(col(\"Registration State\") == \"NY\").groupby(\"Registration State\")\\\n",
    "                        .agg(sum(\"count\").alias(\"count\"))\n",
    "# total number of cars from NY\n",
    "state_replace.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|Registration State|  count|\n",
      "+------------------+-------+\n",
      "|                NY|4290006|\n",
      "|                NJ| 475825|\n",
      "|                PA| 140286|\n",
      "|                CT|  70403|\n",
      "|                FL|  69468|\n",
      "|                IN|  45525|\n",
      "|                MA|  38941|\n",
      "|                VA|  34367|\n",
      "|                MD|  30213|\n",
      "|                NC|  27152|\n",
      "|                TX|  18827|\n",
      "|                IL|  18666|\n",
      "|                GA|  17537|\n",
      "|                AZ|  12379|\n",
      "|                OH|  12281|\n",
      "|                CA|  12153|\n",
      "|                ME|  10806|\n",
      "|                SC|  10395|\n",
      "|                MN|  10083|\n",
      "|                OK|   9088|\n",
      "|                TN|   8514|\n",
      "|                DE|   7905|\n",
      "|                MI|   7231|\n",
      "|                RI|   5814|\n",
      "|                NH|   4119|\n",
      "|                VT|   3683|\n",
      "|                AL|   3178|\n",
      "|                WA|   3052|\n",
      "|                OR|   2622|\n",
      "|                MO|   2483|\n",
      "|                ON|   2460|\n",
      "|                WI|   2127|\n",
      "|                QB|   1998|\n",
      "|                IA|   1938|\n",
      "|                DC|   1929|\n",
      "|                CO|   1841|\n",
      "|                KY|   1795|\n",
      "|                DP|   1794|\n",
      "|                LA|   1689|\n",
      "|                MS|   1582|\n",
      "|                WV|   1265|\n",
      "|                AR|    994|\n",
      "|                SD|    859|\n",
      "|                NM|    792|\n",
      "|                ID|    763|\n",
      "|                NV|    725|\n",
      "|                KS|    706|\n",
      "|                NE|    704|\n",
      "|                UT|    561|\n",
      "|                MT|    505|\n",
      "|                GV|    348|\n",
      "|                NS|    322|\n",
      "|                AK|    298|\n",
      "|                ND|    254|\n",
      "|                WY|    188|\n",
      "|                HI|    156|\n",
      "|                AB|     79|\n",
      "|                PE|     61|\n",
      "|                NB|     57|\n",
      "|                BC|     54|\n",
      "|                PR|     38|\n",
      "|                MB|     17|\n",
      "|                SK|      9|\n",
      "|                FO|      8|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = unique_states.select(\"Registration State\", \"count\")\\\n",
    "                    .where((col(\"Registration State\") != \"NY\") & (col(\"Registration State\") != \"99\"))\\\n",
    "                    .sort(desc(\"count\"))\n",
    "# combining dataframes with NY only count and remaining state counts to get the final dataframe\n",
    "unique_states_count = state_replace.union(temp)\n",
    "unique_states_count.sort(desc(\"count\")).show(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|unique_states_count|\n",
      "+-------------------+\n",
      "|                 64|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the number of unique states from where the cars that got parking tickets came.\n",
    "num_unique_states = unique_states_count.agg(countDistinct(\"Registration State\").alias(\"unique_states_count\"))\n",
    "num_unique_states.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Examine the data: RESULTS\n",
    "##### 1. Find the total number of tickets for the year.\n",
    "##### 5431918\n",
    "\n",
    "##### 2. Find out the number of unique states from where the cars that got parking tickets came.\n",
    "##### 64\n",
    "##### New York state has the highest number of parking tickets which is 4290006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframe into a spark sql table/view\n",
    "tickets = tickets.withColumn(\"Registration State\", regexp_replace(\"Registration State\", \"99\", \"NY\"))\n",
    "\n",
    "tickets.cache()\n",
    "tickets.createOrReplaceTempView(\"v_tickets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|Violation Code|Frequency|\n",
      "+--------------+---------+\n",
      "|            21|   768087|\n",
      "|            36|   662765|\n",
      "|            38|   542079|\n",
      "|            14|   476664|\n",
      "|            20|   319646|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. How often does each violation code occur? Display the frequency of the top five violation codes.\n",
    "violation_code_freq = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Violation Code` ORDER BY Frequency desc LIMIT 5\"\"\") \n",
    "violation_code_freq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|Vehicle Body Type|Frequency|\n",
      "+-----------------+---------+\n",
      "|             SUBN|  1883954|\n",
      "|             4DSD|  1547312|\n",
      "|              VAN|   724029|\n",
      "|             DELV|   358984|\n",
      "|              SDN|   194197|\n",
      "+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2(a).How often does each 'vehicle body type' get a parking ticket?\n",
    "parking_tick_by_vehicle_body_type = spark.sql(\"\"\"SELECT `Vehicle Body Type`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Vehicle Body Type` ORDER BY Frequency desc LIMIT 5\"\"\")\n",
    "parking_tick_by_vehicle_body_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|Vehicle Make|Frequency|\n",
      "+------------+---------+\n",
      "|        FORD|   636844|\n",
      "|       TOYOT|   605291|\n",
      "|       HONDA|   538884|\n",
      "|       NISSA|   462017|\n",
      "|       CHEVR|   356032|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2(b).How often does each 'Vehicle Make' get a parking ticket?\n",
    "parking_tick_by_vehicle_Make = spark.sql(\"\"\"SELECT `Vehicle Make`, count(*) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Vehicle Make` ORDER BY Frequency desc LIMIT 5\"\"\")\n",
    "parking_tick_by_vehicle_Make.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|Violation Precinct|Frequency|\n",
      "+------------------+---------+\n",
      "|                 0|   925596|\n",
      "|                19|   274445|\n",
      "|                14|   203553|\n",
      "|                 1|   174702|\n",
      "|                18|   169131|\n",
      "|               114|   147444|\n",
      "+------------------+---------+\n",
      "\n",
      "+---------------+---------+\n",
      "|Issuer Precinct|Frequency|\n",
      "+---------------+---------+\n",
      "|              0|  1078406|\n",
      "|             19|   266961|\n",
      "|             14|   200495|\n",
      "|              1|   168740|\n",
      "|             18|   162994|\n",
      "|            114|   144054|\n",
      "+---------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Find the (5 highest) frequencies of tickets for each of the following:\n",
    "# Ignoring the entry with Violation & Issue Precinct as 0.\n",
    "#3(a): 'Violation Precinct'\n",
    "parking_tick_by_Violation_Precint = spark.sql(\"\"\"SELECT `Violation Precinct`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Violation Precinct` ORDER BY Frequency desc LIMIT 6\"\"\")\n",
    "parking_tick_by_Violation_Precint.show()\n",
    "\n",
    "#3(b): 'Issuer Precinct'\n",
    "parking_tick_by_Issuer_Precint = spark.sql(\"\"\"SELECT `Issuer Precinct`, count(`Summons Number`) AS Frequency FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 GROUP BY `Issuer Precinct` ORDER BY Frequency desc LIMIT 6\"\"\")\n",
    "parking_tick_by_Issuer_Precint.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precinct 19 tops as the highest number of parking tickets for a Violation Precinct. \n",
    "#### Precinct 19 also tops as the highest number of parking tickets for a Issuer Precinct.\n",
    "#### Address for Precint 19 is 153 E 67th St, New York, NY 10065, USA which means there is a higher number of parking violations happening around the 67th Street in NYC i.e. this area has severe problem of parking space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 19|\n",
      "+--------------+--------------------------------+\n",
      "|            46|                           48445|\n",
      "|            38|                           36386|\n",
      "|            37|                           36056|\n",
      "|            14|                           29797|\n",
      "|            21|                           28415|\n",
      "+--------------+--------------------------------+\n",
      "\n",
      "+--------------+--------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 14|\n",
      "+--------------+--------------------------------+\n",
      "|            14|                           45036|\n",
      "|            69|                           30464|\n",
      "|            31|                           22555|\n",
      "|            47|                           18364|\n",
      "|            42|                           10027|\n",
      "+--------------+--------------------------------+\n",
      "\n",
      "+--------------+-------------------------------+\n",
      "|Violation Code|Freq of Violation Codes Prnct 1|\n",
      "+--------------+-------------------------------+\n",
      "|            14|                          38354|\n",
      "|            16|                          19081|\n",
      "|            20|                          15408|\n",
      "|            46|                          12745|\n",
      "|            38|                           8535|\n",
      "+--------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4. Find the violation code frequencies for three precincts that have issued the most number of tickets\n",
    "# violation code frequncies for the top three precincts with highest frequency of tickets\n",
    "\n",
    "#From above question, we found out that precinct 19, 14 & 1 has issued the most number of parking tickets.\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_19_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 19` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 19 \n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 19` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_19_VCode.show()\n",
    "\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_14_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 14` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 14 \n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 14` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_14_VCode.show()\n",
    "\n",
    "#1. Finding the frequency of violation codes for precinct 19\n",
    "freq_prcnt_1_VCode = spark.sql(\"\"\"SELECT `Violation Code`,count(`Violation Code`) AS `Freq of Violation Codes Prnct 1` \n",
    "                                FROM v_tickets WHERE YEAR(`ISSUE DATE`) = 2017 AND `Issuer Precinct` = 1\n",
    "                                GROUP BY `Violation Code` ORDER BY `Freq of Violation Codes Prnct 1` desc LIMIT 5\"\"\")\n",
    "\n",
    "freq_prcnt_1_VCode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count when column is null 0\n",
      "Count when column has 'nan' value 16\n",
      "+++++++++++AFTER CLEANING THE DATA++++++++++++++\n",
      "Count when column has 'nan': 0\n"
     ]
    }
   ],
   "source": [
    "#5(a) Find a way to deal with missing values\n",
    "from pyspark.sql.functions import isnan, isnull\n",
    "\n",
    "# Filtering Record for year 2017 only\n",
    "tickets_2017 = tickets.filter(year(\"Issue Date\")==2017)\n",
    "\n",
    "# Checking null or nan values in the Violation Time field\n",
    "null_count = tickets_2017.where(col(\"Violation Time\") == \"null\").count()\n",
    "print(\"Count when column is null\", null_count)\n",
    "\n",
    "nan_count = tickets_2017.where(col(\"Violation Time\") == \"nan\").count()\n",
    "print(\"Count when column has 'nan' value\", nan_count)\n",
    "\n",
    "#Since, the count of nan values is quite low, so we are safe to drop the rows with nan values \n",
    "#as it won't affect our results much.\n",
    "print(\"+++++++++++AFTER CLEANING THE DATA++++++++++++++\")\n",
    "tickets_2017_filtered = tickets_2017.filter(col(\"Violation Time\") != \"nan\")\n",
    "print(\"Count when column has 'nan':\", tickets_2017_filtered.filter(col(\"Violation Time\") == \"nan\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Hour|Minutes|TimeOfDay|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|  11|     20|        A|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|  08|     52|        P|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|  00|     15|        A|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|  05|     25|        A|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|  02|     56|        P|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      " |-- Hour: string (nullable = true)\n",
      " |-- Minutes: string (nullable = true)\n",
      " |-- TimeOfDay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b)The Violation Time field is specified in a strange format. \n",
    "#    Find a way to make this a time attribute that you can use to divide into groups.\n",
    "\n",
    "#converting the Violation Time column to timestamp\n",
    "from pyspark.sql.functions import substring\n",
    "\n",
    "tickets_2017_hour = tickets_2017_filtered.withColumn(\"Hour\",col(\"Violation Time\").substr(1,2))\n",
    "tickets_2017_min = tickets_2017_hour.withColumn(\"Minutes\", col(\"Violation Time\").substr(3,2))\n",
    "tickets_2017_new = tickets_2017_min.withColumn(\"TimeOfDay\",col(\"Violation Time\").substr(5,1))\n",
    "tickets_2017_new.show(5)\n",
    "tickets_2017_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Hour|Minutes|TimeOfDay|Time of the Day|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|  11|     20|        A|   LATE MORNING|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|   8|     52|        P|          NIGHT|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11 00:00:00|            78|             DELV|       FRUEH|               106|            106|         0015A|   0|     15|        A|           DAWN|\n",
      "|    1413656420|T672371C|                NY|2017-02-04 00:00:00|            40|             TAXI|       TOYOT|                73|             73|         0525A|   5|     25|        A|        MORNING|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26 00:00:00|            64|              VAN|       INTER|                17|             17|         0256P|   2|     56|        P|      AFTERNOON|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----+-------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b)Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. \n",
    "#    For each of these groups, find the three most commonly occurring violations.\n",
    "tickets_2017_new=tickets_2017_new.withColumn(\"Hour\",col(\"Hour\").cast(\"integer\"))\n",
    "tickets_2017_new=tickets_2017_new.withColumn(\"Minutes\",col(\"Minutes\").cast(\"integer\"))\n",
    "\n",
    "# creating view after removing the null or nan values from Violation Field\n",
    "tickets_2017_new.createOrReplaceTempView(\"tickets_2017_new\")\n",
    "\n",
    "#5(b:1) Dividing Violation Time into 6 buckets\n",
    "violation_time_interval = spark.sql(\"\"\"SELECT *, CASE WHEN (HOUR IN (0,1,2,3,12)) THEN CASE WHEN (TimeOfDay==\"A\") THEN \"DAWN\" ELSE \"AFTERNOON\" END WHEN (HOUR IN (4,5,6,7)) THEN CASE WHEN (TimeOfDay==\"A\") THEN \"MORNING\" ELSE \"DUSK\" END WHEN (HOUR IN (8,9,10,11) AND (TimeOfDay==\"A\")) THEN \"LATE MORNING\" ELSE \"NIGHT\" END AS `Time of the Day` FROM tickets_2017_new\"\"\")\n",
    "\n",
    "violation_time_interval.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divided the Violation Time into 6 time intervals:\n",
    "#### 1. DAWN - 00 HRS to 03 Hrs (AM)\n",
    "#### 2. MORNING - 04 HRS to 07 Hrs (AM)\n",
    "#### 3. LATE MORNING - 08 HRS to 11 Hrs (AM)\n",
    "#### 4. AFTERNOON - 12 HRS to 03 Hrs (PM)\n",
    "#### 5. DUSK - 04 HRS to 07 Hrs (PM)\n",
    "#### 6. NIGHT - 08 HRS to 11 Hrs (PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three most common violation in DAWN:\n",
      "\n",
      "+--------------+----------------+\n",
      "|Violation Code|count_VCode_dawn|\n",
      "+--------------+----------------+\n",
      "|            21|           36958|\n",
      "|            40|           25867|\n",
      "|            78|           15528|\n",
      "+--------------+----------------+\n",
      "\n",
      "Three most common violation in MORNING:\n",
      "\n",
      "+--------------+-------------------+\n",
      "|Violation Code|count_VCode_morning|\n",
      "+--------------+-------------------+\n",
      "|            14|              74114|\n",
      "|            40|              60652|\n",
      "|            21|              57897|\n",
      "+--------------+-------------------+\n",
      "\n",
      "Three most common violation in LATE MORNING:\n",
      "\n",
      "+--------------+--------------------+\n",
      "|Violation Code|count_VCode_late_mor|\n",
      "+--------------+--------------------+\n",
      "|            21|              598069|\n",
      "|            36|              348165|\n",
      "|            38|              176570|\n",
      "+--------------+--------------------+\n",
      "\n",
      "Three most common violation in AFTERNOON:\n",
      "\n",
      "+--------------+-----------------+\n",
      "|Violation Code|count_VCode_aftrn|\n",
      "+--------------+-----------------+\n",
      "|            36|           286284|\n",
      "|            38|           240721|\n",
      "|            37|           167026|\n",
      "+--------------+-----------------+\n",
      "\n",
      "Three most common violation in DUSK:\n",
      "\n",
      "+--------------+----------------+\n",
      "|Violation Code|count_VCode_dusk|\n",
      "+--------------+----------------+\n",
      "|            38|          102855|\n",
      "|            14|           75902|\n",
      "|            37|           70345|\n",
      "+--------------+----------------+\n",
      "\n",
      "Three most common violation in NIGHT:\n",
      "\n",
      "+--------------+-----------------+\n",
      "|Violation Code|count_VCode_night|\n",
      "+--------------+-----------------+\n",
      "|             7|            26293|\n",
      "|            40|            22343|\n",
      "|            14|            21046|\n",
      "+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b:2) three most occuring violations for each time interval\n",
    "violation_time_interval.cache()\n",
    "violation_time_interval.createOrReplaceTempView(\"violation_per_time_interval\")\n",
    "# 3 most violation for dawn\n",
    "three_most_violation_dawn = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_dawn FROM violation_per_time_interval WHERE `Time of the Day`== \"DAWN\" GROUP BY `Violation Code` ORDER BY `count_VCode_dawn` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in DAWN:\\n\")\n",
    "three_most_violation_dawn.show()\n",
    "\n",
    "# 3 most violation for morning\n",
    "three_most_violation_morning = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_morning FROM violation_per_time_interval WHERE `Time of the Day`== \"MORNING\" GROUP BY `Violation Code` ORDER BY `count_VCode_morning` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in MORNING:\\n\")\n",
    "three_most_violation_morning.show()\n",
    "\n",
    "# 3 most violation for late morning\n",
    "three_most_violation_late_morning = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_late_mor FROM violation_per_time_interval WHERE `Time of the Day`== \"LATE MORNING\" GROUP BY `Violation Code` ORDER BY `count_VCode_late_mor` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in LATE MORNING:\\n\")\n",
    "three_most_violation_late_morning.show()\n",
    "\n",
    "# 3 most violation for afternoon\n",
    "three_most_violation_afternoon = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_aftrn FROM violation_per_time_interval WHERE `Time of the Day`== \"AFTERNOON\" GROUP BY `Violation Code` ORDER BY `count_VCode_aftrn` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in AFTERNOON:\\n\")\n",
    "three_most_violation_afternoon.show()\n",
    "\n",
    "# 3 most violation for dusk\n",
    "three_most_violation_dusk= spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_dusk FROM violation_per_time_interval WHERE `Time of the Day`== \"DUSK\" GROUP BY `Violation Code` ORDER BY `count_VCode_dusk` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in DUSK:\\n\")\n",
    "three_most_violation_dusk.show()\n",
    "\n",
    "# 3 most violation for night\n",
    "three_most_violation_night = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) As count_VCode_night FROM violation_per_time_interval WHERE `Time of the Day`== \"NIGHT\" GROUP BY `Violation Code` ORDER BY `count_VCode_night` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common violation in NIGHT:\\n\")\n",
    "three_most_violation_night.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three most common occuring violation codes \n",
      "\n",
      "+--------------+-----------------------+\n",
      "|Violation Code|Three_most_common_VCode|\n",
      "+--------------+-----------------------+\n",
      "|            21|                 768087|\n",
      "|            36|                 662765|\n",
      "|            38|                 542079|\n",
      "+--------------+-----------------------+\n",
      "\n",
      "Common time of the day for violation code 21\n",
      "+-------------+---------------+\n",
      "|VCode_21_freq|Time of the Day|\n",
      "+-------------+---------------+\n",
      "|       598069|   LATE MORNING|\n",
      "|        74695|      AFTERNOON|\n",
      "|        57897|        MORNING|\n",
      "|        36958|           DAWN|\n",
      "|          259|           DUSK|\n",
      "|          209|          NIGHT|\n",
      "+-------------+---------------+\n",
      "\n",
      "Common time of the day for violation code 36\n",
      "+-------------+---------------+\n",
      "|VCode_36_freq|Time of the Day|\n",
      "+-------------+---------------+\n",
      "|       348165|   LATE MORNING|\n",
      "|       286284|      AFTERNOON|\n",
      "|        14782|        MORNING|\n",
      "|        13534|           DUSK|\n",
      "+-------------+---------------+\n",
      "\n",
      "Common time of the day for violation code 38\n",
      "+-------------+---------------+\n",
      "|VCode_38_freq|Time of the Day|\n",
      "+-------------+---------------+\n",
      "|       240721|      AFTERNOON|\n",
      "|       176570|   LATE MORNING|\n",
      "|       102855|           DUSK|\n",
      "|        20348|          NIGHT|\n",
      "|         1273|        MORNING|\n",
      "|          312|           DAWN|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5(b:3) For the three most commonly occurring violation codes, find the most common time of the day\n",
    "common_time_for_violation = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) as Three_most_common_VCode \n",
    "            FROM violation_per_time_interval GROUP BY `Violation Code` ORDER BY `Three_most_common_VCode` DESC LIMIT 3\"\"\")\n",
    "print(\"Three most common occuring violation codes \\n\")\n",
    "common_time_for_violation.show()\n",
    "\n",
    "#most common time of the day for violation code 21\n",
    "print(\"Common time of the day for violation code 21\")\n",
    "common_time_vcode_21= spark.sql(\"\"\"SELECT count(`Summons Number`) AS `VCode_21_freq`, `Time of the Day` \n",
    "                            FROM violation_per_time_interval WHERE `Violation Code` = 21 GROUP BY `Time of the Day` \n",
    "                            ORDER BY `VCode_21_freq` DESC\"\"\")\n",
    "common_time_vcode_21.show()\n",
    "\n",
    "#most common time of the day for violation code 36\n",
    "print(\"Common time of the day for violation code 36\")\n",
    "common_time_vcode_36= spark.sql(\"\"\"SELECT count(`Summons Number`) AS `VCode_36_freq`, `Time of the Day` \n",
    "                            FROM violation_per_time_interval WHERE `Violation Code` = 36 GROUP BY `Time of the Day` \n",
    "                            ORDER BY `VCode_36_freq` DESC\"\"\")\n",
    "common_time_vcode_36.show()\n",
    "\n",
    "#most common time of the day for violation code 38\n",
    "print(\"Common time of the day for violation code 38\")\n",
    "common_time_vcode_38= spark.sql(\"\"\"SELECT count(`Summons Number`) AS `VCode_38_freq`, `Time of the Day` \n",
    "                            FROM violation_per_time_interval WHERE `Violation Code` = 38 GROUP BY `Time of the Day` \n",
    "                            ORDER BY `VCode_38_freq` DESC\"\"\")\n",
    "common_time_vcode_38.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Let’s try and find some seasonality in this data:\n",
    "First, divide the year into a certain number of seasons, and find the frequencies of tickets for each season. (Hint: Use Issue Date to segregate into seasons.)\n",
    "Then, find the three most common violations for each of these seasons..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this first we convert string issue date into date \n",
    "* then we extract month from it \n",
    "* according to month we will assign season.\n",
    "* count number of tickits for each season\n",
    "* then we count top 3 code for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         0525A|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         0256P|\n",
      "|    1416638830|  GLP367|                NY|2017-04-30|            20|             SUBN|       DODGE|                17|             17|         1232A|\n",
      "|    4630524241|  HJBP29|                FL|2017-02-03|            36|               4D|         BMW|                 0|              0|         1034A|\n",
      "|    8505131836| 87155MA|                NY|2017-05-27|            38|              VAN|       CHEVR|                 1|              1|         1021A|\n",
      "|    8513520615| 77026MG|                NY|2017-05-31|            14|             TRAC|       VOLVO|                24|             24|         0721A|\n",
      "|    8556155431| HFB9919|                NY|2017-05-26|            75|             4DSD|       DODGE|               114|            114|         0940A|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting Issue Date as Date Type\n",
    "tickets_2017=tickets_2017.withColumn(\"Issue Date\", tickets_2017[\"Issue Date\"].cast(\"date\"))\n",
    "tickets_2017.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Month|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|    6|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|    6|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|    1|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         0525A|    2|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         0256P|    1|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracting month from the Issue Date column\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "\n",
    "ticket_month=tickets_2017.withColumn(\"Month\", month(\"Issue Date\"))\n",
    "ticket_month.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|Month|Season|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14|            47|             REFG|       MITSU|                14|             14|         1120A|    6|SUMMER|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13|             7|             SUBN|       ME/BE|                 0|              0|         0852P|    6|SUMMER|\n",
      "|    1407740258| 2513JMG|                NY|2017-01-11|            78|             DELV|       FRUEH|               106|            106|         0015A|    1|WINTER|\n",
      "|    1413656420|T672371C|                NY|2017-02-04|            40|             TAXI|       TOYOT|                73|             73|         0525A|    2|SUMMER|\n",
      "|    8480309064| 51771JW|                NY|2017-01-26|            64|              VAN|       INTER|                17|             17|         0256P|    1|WINTER|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Frequencies of tickets for each Season:\n",
      "\n",
      "+-------+----------------------------------+\n",
      "| Season|Freq of Parking Tickets Per Season|\n",
      "+-------+----------------------------------+\n",
      "| SUMMER|                           4552537|\n",
      "| WINTER|                            878061|\n",
      "|MONSOON|                              1320|\n",
      "+-------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6(a:1) Assigning seasons based on month\n",
    "#creating view from the dataframe\n",
    "ticket_month.createOrReplaceTempView(\"v_tickets_month\")\n",
    "\n",
    "tickets_season=spark.sql(\"\"\"SELECT *,CASE WHEN Month in (7,8,9,10) THEN \"MONSOON\" WHEN Month in (2,3,4,5,6) THEN \"SUMMER\" ELSE \"WINTER\" END AS Season FROM v_tickets_month\"\"\")\n",
    "tickets_season.show(5)\n",
    "\n",
    "#creating view from the dataframe\n",
    "tickets_season.createOrReplaceTempView(\"v_tickets_season\")\n",
    "\n",
    "#6(a:2) finding the frequencies of tickets for each season\n",
    "tickets_season_freq = spark.sql(\"\"\"SELECT `Season`, count(`Summons Number`) as `Freq of Parking Tickets Per Season` \n",
    "                            FROM v_tickets_season GROUP BY `Season` ORDER BY `Freq of Parking Tickets Per Season` DESC\"\"\")\n",
    "                                \n",
    "print(\"Frequencies of tickets for each Season:\\n\")\n",
    "tickets_season_freq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summer has the higest frequency of parking tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 common violation codes in Winter Season:\n",
      "\n",
      "+--------------+---------------+\n",
      "|Violation Code|VCode_wint_freq|\n",
      "+--------------+---------------+\n",
      "|            36|         129769|\n",
      "|            21|         119931|\n",
      "|            38|          95451|\n",
      "+--------------+---------------+\n",
      "\n",
      "3 common violation codes in Summer Season:\n",
      "\n",
      "+--------------+--------------+\n",
      "|Violation Code|VCode_sum_freq|\n",
      "+--------------+--------------+\n",
      "|            21|        647909|\n",
      "|            36|        532996|\n",
      "|            38|        446618|\n",
      "+--------------+--------------+\n",
      "\n",
      "3 common violation codes in Monsoon Season:\n",
      "\n",
      "+--------------+--------------+\n",
      "|Violation Code|VCode_mon_freq|\n",
      "+--------------+--------------+\n",
      "|            46|           287|\n",
      "|            21|           247|\n",
      "|            40|           146|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6(b) 3 most common violations per season\n",
    "#Winter\n",
    "tickets_winter = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) AS `VCode_wint_freq` \n",
    "                            FROM v_tickets_season WHERE  `Season`=\"WINTER\" GROUP BY `Violation Code` \n",
    "                            ORDER BY `VCode_wint_freq` DESC LIMIT 3\"\"\")\n",
    "print(\"3 common violation codes in Winter Season:\\n\")\n",
    "tickets_winter.show()\n",
    "\n",
    "#Summer\n",
    "tickets_summer = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) AS `VCode_sum_freq` \n",
    "                            FROM v_tickets_season WHERE  `Season`=\"SUMMER\" GROUP BY `Violation Code` \n",
    "                            ORDER BY `VCode_sum_freq` DESC LIMIT 3\"\"\")\n",
    "print(\"3 common violation codes in Summer Season:\\n\")\n",
    "tickets_summer.show()\n",
    "\n",
    "#Monsoon\n",
    "tickets_monsoon = spark.sql(\"\"\"SELECT `Violation Code`, count(`Summons Number`) AS `VCode_mon_freq` \n",
    "                            FROM v_tickets_season WHERE  `Season`=\"MONSOON\" GROUP BY `Violation Code` \n",
    "                            ORDER BY `VCode_mon_freq` DESC LIMIT 3\"\"\")\n",
    "print(\"3 common violation codes in Monsoon Season:\\n\")\n",
    "tickets_monsoon.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Summer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Monsson **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Summer and Winter, we get common violation codes in top 3 which are 21,36,38.\n",
    "* For Monsoon, common violation codes in top 3  are 46,21,40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating this for the three most commonly occurring codes:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We count number of ticket for each code then we multiply top 3 code with find which we get from previous question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of three most violation codes:\n",
      "\n",
      "+--------------+-------+\n",
      "|Violation code|  count|\n",
      "+--------------+-------+\n",
      "|          null|5431918|\n",
      "|            21| 768087|\n",
      "|            36| 662765|\n",
      "|            38| 542079|\n",
      "+--------------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7(a) top 3 violation codes\n",
    "tickets_fine=tickets_2017.cube('Violation code').count().sort(col('count').desc())\n",
    "print(\"Occurrences of three most violation codes:\\n\")\n",
    "tickets_fine.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total amount of fine for violation code 21\n",
      "+--------------+--------------------+\n",
      "|Violation code|Total Fine Collected|\n",
      "+--------------+--------------------+\n",
      "|            21|            42244785|\n",
      "+--------------+--------------------+\n",
      "\n",
      "total amount of fine for violation code 36\n",
      "+--------------+--------------------+\n",
      "|Violation code|Total Fine Collected|\n",
      "+--------------+--------------------+\n",
      "|            36|            33138250|\n",
      "+--------------+--------------------+\n",
      "\n",
      "total amount of fine for violation code 38\n",
      "+--------------+--------------------+\n",
      "|Violation code|Total Fine Collected|\n",
      "+--------------+--------------------+\n",
      "|            38|            27103950|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7(b)\n",
    "# creating table from dataframe\n",
    "tickets_fine.createOrReplaceTempView(\"v_tickets_fine\")\n",
    "\n",
    "#Violation code 21\n",
    "print(\"total amount of fine for violation code 21\")\n",
    "vc21_total_fine=spark.sql(\"\"\"select `Violation code`,cast(`count`*((65+45)/2) as int) as `Total Fine Collected` \n",
    "                                  from v_tickets_fine where `Violation code` =\"21\" \"\"\")\n",
    "vc21_total_fine.show()\n",
    "\n",
    "#Violation code 36\n",
    "print(\"total amount of fine for violation code 36\")\n",
    "vc36_total_fine=spark.sql(\"\"\"select `Violation code`,cast(`count`*((50+50)/2) as int) as `Total Fine Collected` \n",
    "                              from v_tickets_fine where `Violation code` =\"36\" \"\"\")\n",
    "vc36_total_fine.show()\n",
    "\n",
    "#Violation code 38\n",
    "print(\"total amount of fine for violation code 38\")\n",
    "vc38_total_fine=spark.sql(\"\"\"select `Violation code`,cast(`count`*((65+35)/2) as int) as `Total Fine Collected` \n",
    "                                  from v_tickets_fine where `Violation code` =\"38\" \"\"\")\n",
    "vc38_total_fine.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopping the spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
